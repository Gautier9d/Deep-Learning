import streamlit as st
import os
import pandas as pd
import numpy as np

def render_readme():
    st.title("DeepDog: Deep Learning for Dog Whistle Detection")
    st.markdown("EPFL's EE-559 - Deep Learning Project Repository")
    
    # Display badges in a single line
    badges = [
        '[![Open Source Love](https://firstcontributions.github.io/open-source-badges/badges/open-source-v2/open-source.svg)](https://github.com/firstcontributions/open-source-badges)',
        '[![License: MIT](https://img.shields.io/badge/License-MIT-red.svg)](https://opensource.org/licenses/MIT)',
        '[![GitHub](https://img.shields.io/badge/GitHub-%23121011.svg?logo=github&logoColor=white)](https://github.com/Gautier9d/DeepDog)',
        '[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://deepdog.streamlit.app/)'
    ]
    st.markdown(' '.join(badges), unsafe_allow_html=True)
    
    st.image(os.path.join("assets", "banner.png"), use_container_width=True)
    st.caption("Image generated by ChatGPT")

    st.warning("⚠️ WARNING: This repository contains content that are offensive and/or hateful in nature as part of the research dataset and examples.")

    st.header("Abstract")
    st.markdown("""
We present DeepDog, a transformer-based framework for detecting and analyzing coded language ("dog whistles") in online content. The framework supports multiple pre-trained models (BERT, DistilBERT, HateBERT, and HateXplain) and implements parameter-efficient fine-tuning through Low-Rank Adaptation (LoRA). Evaluated on the SALT-NLP Silent Signals dataset, the models we used demonstrate robust performance in identifying dog whistle. Additionally, the project includes environmental impact tracking, visualizing the carbon footprint of model training in terms of real-world equivalents.
    """)

    st.header("The Challenge of Dog Whistle Detection")
    st.markdown("The following example demonstrates the complexity and subtlety involved in detecting dog whistles in text. Two different LLMs when asked the same question yield contradicting interpretations, highlighting why advanced ML techniques are necessary for this task:")
    col1, col2 = st.columns(2)
    with col1:
        st.image(os.path.join("assets", "grok_output.png"), caption="Grok: Identifies the text as containing coded language", use_container_width=True)
    with col2:
        st.image(os.path.join("assets", "chatgpt_output.png"), caption="ChatGPT: Labels the same text as innocuous", use_container_width=True)

    st.header("Key Features")
    st.markdown("""
- **Multi-Model Support**: Compatible with BERT, DistilBERT, HateBERT, and HateXplain
- **Efficient Fine-tuning**: Implements LoRA for parameter-efficient model adaptation
- **Environmental Tracking**: Monitors and reports carbon emissions during training
- **Comprehensive Metrics**: Evaluates using IOU, F1 Score, and AUPRC metrics
    """)

    st.header("Environmental Impact")
    st.markdown("The project includes built-in carbon emission tracking using [codecarbon](https://github.com/mlco2/codecarbon). Training results include visualizations of:")
    st.markdown("- Equivalent car miles driven\n- Percentage of weekly American household emissions")

    st.header("Experiment Tracking")
    st.markdown("All experiments and model artifacts are tracked using Weights & Biases (W&B). You can explore our training runs, model performance, and artifacts at: [https://wandb.ai/gopald/deep-dog](https://wandb.ai/gopald/deep-dog)")

    st.header("Results")
    st.markdown("### Model Performance and Environmental Impact")

    # Define the metrics and data
    metrics = ["IoU", "F1", "AUPRC", "Emissions", "Car km", "House Fraction (%)"]
    
    # Create the data as a list of lists for proper shape
    data = [
        # IoU row
        ["75.82", "76.58", "73.59", "75.81", "63.28", "61.91", "61.79", "61.25"],
        # F1 row
        ["86.25", "86.73", "84.79", "86.24", "77.51", "76.47", "76.39", "75.97"],
        # AUPRC row
        ["92.81", "92.75", "91.50", "92.37", "83.67", "83.27", "82.75", "82.48"],
        # Emissions row
        ["0.46", "10.30", "10.20", "10.30", "0.42", "0.76", "0.78", "0.77"],
        # Car km row
        ["1.82", "40.50", "40.00", "40.50", "1.67", "2.97", "3.04", "3.03"],
        # House Fraction row
        ["0.29", "6.41", "6.32", "6.40", "0.26", "0.47", "0.48", "0.48"]
    ]
    
    columns = [
        "FT-DistilBERT", "FT-BERT", "FT-hateBERT", "FT-HateXplain",
        "LoRA-DistilBERT", "LoRA-BERT", "LoRA-hateBERT", "LoRA-HateXplain"
    ]

    # Create DataFrame
    combined_data = pd.DataFrame(data, index=metrics, columns=columns)

    # Create style DataFrame with the same shape
    styles = pd.DataFrame(
       
        index=metrics,
        columns=columns
    )
    
    # Apply styling
    styled_df = combined_data.style.apply(lambda _: styles, axis=None)
    
    # Display the combined table with a legend
    st.markdown("##### Model Types:")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**FT-**: Fine-tuned Models")
    with col2:
        st.markdown("**LoRA-**: LoRA + Fine-tuned Models")
    
    st.table(styled_df)

    st.markdown("""
    **Metric Descriptions:**
    - **IoU**: Intersection over Union score for rationale prediction
    - **F1**: F1 score for rationale prediction
    - **AUPRC**: Area Under the Precision-Recall Curve
    - **Emissions**: CO₂ emissions in kg x 10⁻³
    - **Car km**: Equivalent car kilometers driven x 10⁻³
    - **House Fraction**: Percentage of weekly American household emissions x 10⁻³
    """)
    
    # Display carbon emissions visualization
    st.markdown("### Carbon Emissions Comparison")
    st.markdown("Visual comparison of carbon emissions during training between standard fine-tuning and LoRA approaches:")
    st.image(os.path.join("assets", "carbon_emissions.png"), 
            caption="Carbon Emissions Comparison across Different Models", 
            use_container_width=True)
    

    st.header("Course Information and Contributors")
    st.markdown("""
- **Course**: EE-559 - Deep Learning
- **Teacher**: Cavallaro Andrea
- **Group**: Romain Nicolas Paul Couyoumtzelis, Gopal Ramesh Dahale, Gautier Demierre
    """)

    st.header("References")
    st.markdown("""
1. Silent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded Dog Whistles  
   Julia Kruk, et al.  
   [arXiv:2406.06840](https://arxiv.org/abs/2406.06840)
2. LoRA: Low-Rank Adaptation of Large Language Models  
   Edward J. Hu, et al.  
   [arXiv:2106.09685](https://arxiv.org/abs/2106.09685)
3. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding  
   Jacob Devlin, et al.  
   [arXiv:1810.04805](https://arxiv.org/abs/1810.04805)
4. DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter  
   Victor Sanh, et al.  
   [arXiv:1910.01108](https://arxiv.org/abs/1910.01108)
5. HateBERT: Retraining BERT for Abusive Language Detection in English  
   Tommy Liu, et al.  
   [arXiv:2010.12472](https://arxiv.org/abs/2010.12472)
    """)

    st.header("Acknowledgments")
    st.markdown("""
- Project structure and code quality standards were inspired by [Full Stack Deep Learning](https://github.com/the-full-stack/fsdl-text-recognizer-2021-labs) course materials.
- Parts of this project's code were developed with assistance from Large Language Models (LLMs). This way, we want to promote code quality and development efficiency while maintaining transparency about the tools.
    """)

    st.header("Citation")
    st.markdown("If you use this code in your research, please cite:")
    st.code("""@misc{deepdog2025,
    title={DeepDog: Deep Learning for Dog Whistle Detection},
    author={Romain Nicolas Paul Couyoumtzelis, Gopal Ramesh Dahale, Gautier Demierre},
    year={2025},
    publisher={GitHub},
    journal={GitHub repository},
    howpublished={https://github.com/Gautier9d/DeepDog}
}""", language="bibtex")
